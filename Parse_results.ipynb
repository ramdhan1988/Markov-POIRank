{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_suffix = ['Edin', 'Glas', 'Melb', 'Osak', 'Toro']\n",
    "dat_names = ['Edinburgh', 'Glasgow', 'Melbourne', 'Osaka', 'Toronto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_all = ['\\\\textsc{Random}', '\\\\textsc{PersTour}', '\\\\textsc{PersTour-L}', '\\\\textsc{PoiPopularity}', \\\n",
    "               '\\\\textsc{PoiRank}', '\\\\textsc{Markov}', '\\\\textsc{MarkovPath}', \\\n",
    "               '\\\\textsc{Rank+Markov}', '\\\\textsc{Rank+MarkovPath}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex Table for Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fname(dat_ix):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    \n",
    "    suffix = dat_suffix[dat_ix] + '.pkl'\n",
    "    \n",
    "    frank = os.path.join(data_dir, 'rank-' + suffix)\n",
    "    ftran = os.path.join(data_dir, 'tran-' + suffix)\n",
    "    fcomb = os.path.join(data_dir, 'comb-' + suffix)\n",
    "    frand = os.path.join(data_dir, 'rand-' + suffix)\n",
    "    fijcai = os.path.join(data_dir, 'ijcai-' + dat_suffix[dat_ix] + '.pkl')\n",
    "    return frank, ftran, fcomb, frand, fijcai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_F1(traj_act, traj_rec, noloop=False):\n",
    "    '''Compute recall, precision and F1 for recommended trajectories'''\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(len(traj_act) > 0)\n",
    "    assert(len(traj_rec) > 0)\n",
    "    \n",
    "    if noloop == True:\n",
    "        intersize = len(set(traj_act) & set(traj_rec))\n",
    "    else:\n",
    "        match_tags = np.zeros(len(traj_act), dtype=np.bool)\n",
    "        for poi in traj_rec:\n",
    "            for j in range(len(traj_act)):\n",
    "                if match_tags[j] == False and poi == traj_act[j]:\n",
    "                    match_tags[j] = True\n",
    "                    break\n",
    "        intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "        \n",
    "    recall = intersize / len(traj_act)\n",
    "    precision = intersize / len(traj_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the pairs-F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "cpdef float calc_pairsF1(y, y_hat):\n",
    "    assert(len(y) > 0)\n",
    "    assert(len(y) == len(set(y))) # no loops in y\n",
    "    cdef int n, nr, n0, n0r, nc, poi1, poi2, i, j\n",
    "    n = len(y)\n",
    "    nr = len(y_hat)\n",
    "    n0 = n*(n-1) // 2\n",
    "    n0r = nr*(nr-1) // 2\n",
    "    \n",
    "    # y determines the correct visiting order\n",
    "    order_dict = dict()\n",
    "    for i in range(n):\n",
    "        order_dict[y[i]] = i\n",
    "        \n",
    "    nc = 0\n",
    "    for i in range(nr):\n",
    "        poi1 = y_hat[i]\n",
    "        for j in range(i+1, nr):\n",
    "            poi2 = y_hat[j]\n",
    "            if poi1 in order_dict and poi2 in order_dict and poi1 != poi2:\n",
    "                if order_dict[poi1] < order_dict[poi2]: nc += 1\n",
    "\n",
    "    cdef float precision, recall, F1\n",
    "    precision = (1.0 * nc) / (1.0 * n0r)\n",
    "    recall = (1.0 * nc) / (1.0 * n0)\n",
    "    if nc == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2. * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(dat_ix):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    \n",
    "    frank, ftran, fcomb, frand, fijcai = gen_fname(dat_ix)\n",
    "    #print(frank)\n",
    "    assert(os.path.exists(frank))\n",
    "    #print(ftran)\n",
    "    assert(os.path.exists(ftran))\n",
    "    #print(fcomb)\n",
    "    assert(os.path.exists(fcomb))\n",
    "    #print(frand)\n",
    "    assert(os.path.exists(frand))\n",
    "    #print(fijcai)\n",
    "    assert(os.path.exists(fijcai))\n",
    "\n",
    "    # load results data\n",
    "    recdict_rank = pickle.load(open(frank, 'rb'))\n",
    "    recdict_tran = pickle.load(open(ftran, 'rb'))\n",
    "    recdict_comb = pickle.load(open(fcomb, 'rb'))\n",
    "    recdict_rand = pickle.load(open(frand, 'rb'))\n",
    "    recdict_ijcai = pickle.load(open(fijcai, 'rb'))\n",
    "    \n",
    "    return recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1-scores from loaded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai, func):\n",
    "    assert(isinstance(func, types.FunctionType) or isinstance(func, types.BuiltinFunctionType))\n",
    "    \n",
    "    # deal with missing values: \n",
    "    # get rid of recommendation that not all method are successful, due to ILP timeout.\n",
    "    assert(np.all(sorted(recdict_rank.keys()) == sorted(recdict_tran.keys())))\n",
    "    assert(np.all(sorted(recdict_rank.keys()) == sorted(recdict_comb.keys())))\n",
    "    \n",
    "    keys_all = sorted(recdict_ijcai.keys() & recdict_rank.keys())\n",
    "    \n",
    "    rank1 = []; rank2 = []\n",
    "    for key in keys_all:\n",
    "        rank1.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_POP']))\n",
    "        rank2.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_FEATURE']))\n",
    "    \n",
    "    tran1 = []; tran2 = []\n",
    "    for key in keys_all:\n",
    "        tran1.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_DP']))\n",
    "        tran2.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_ILP']))\n",
    "\n",
    "    comb1 = []; comb2 = []\n",
    "    for key in keys_all:\n",
    "        comb1.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_DP']))\n",
    "        comb2.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_ILP']))\n",
    "            \n",
    "    rand = []\n",
    "    for key in keys_all:\n",
    "        rand.append(func(recdict_rand[key]['REAL'], recdict_rand[key]['REC_RAND']))\n",
    "    \n",
    "    ijcai05T = []; ijcai05L = []\n",
    "    for key in keys_all:\n",
    "        ijcai05T.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05T']))\n",
    "        ijcai05L.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05L']))\n",
    "    \n",
    "    metrics = [rand, ijcai05T, ijcai05L, rank1, rank2, tran1, tran2, comb1, comb2]\n",
    "    means = [np.mean(x) for x in metrics]\n",
    "    stds  = [np.std(x)  for x in metrics]\n",
    "    \n",
    "    # new code\n",
    "    lens = [len(x) for x in metrics]\n",
    "    \n",
    "    # return means, stds\n",
    "\n",
    "    return means, stds, lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex tables from calculated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_latex_table(mean_df, std_df, ismax_df, ismax2nd_df, title, label):    \n",
    "    strs = []\n",
    "    strs.append('\\\\begin{table*}[t]\\n')\n",
    "    strs.append('\\\\caption{' + title + '}\\n')\n",
    "    strs.append('\\\\label{' + label + '}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\begin{tabular}{l|' + (mean_df.shape[1])*'c' + '} \\\\hline\\n')\n",
    "    for col in mean_df.columns:\n",
    "        strs.append(' & ' + col)\n",
    "    strs.append(' \\\\\\\\ \\\\hline\\n')\n",
    "    for ix in mean_df.index:\n",
    "        for j in range(mean_df.shape[1]):\n",
    "            if j == 0: strs.append(ix + ' ')\n",
    "            jx = mean_df.columns[j]\n",
    "            strs.append('& $')\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('\\\\mathbf{')\n",
    "            if ismax2nd_df.loc[ix, jx] == True: strs.append('\\\\mathit{')\n",
    "            strs.append('%.3f' % mean_df.loc[ix, jx] + '\\\\pm' + '%.3f' % std_df.loc[ix, jx])\n",
    "            if ismax_df.loc[ix, jx] == True or ismax2nd_df.loc[ix, jx] == True: strs.append('}')\n",
    "            strs.append('$ ')\n",
    "        strs.append('\\\\\\\\\\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n')\n",
    "    return ''.join(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate evaluation data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = calc_F1\n",
    "# func = calc_pairsF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[t]\n",
      "\\caption{Performance comparison on five datasets in terms of F$_1$ scores. \n",
      "    The best method for each dataset (i.e., a column) is shown in bold, the second best is shown in italic.}\n",
      "\\label{tab:f1}\n",
      "\\centering\n",
      "\\begin{tabular}{l|ccccc} \\hline\n",
      " & Edinburgh & Glasgow & Melbourne & Osaka & Toronto \\\\ \\hline\n",
      "\\textsc{Random} & $0.570\\pm0.139$ & $0.632\\pm0.108$ & $0.558\\pm0.149$ & $0.618\\pm0.129$ & $0.605\\pm0.118$ \\\\\n",
      "\\textsc{PersTour} & $0.656\\pm0.223$ & $\\mathbf{0.801\\pm0.213}$ & $0.483\\pm0.208$ & $0.686\\pm0.231$ & $\\mathbf{0.720\\pm0.215}$ \\\\\n",
      "\\textsc{PersTour-L} & $0.651\\pm0.143$ & $0.660\\pm0.102$ & $0.576\\pm0.141$ & $0.686\\pm0.137$ & $0.643\\pm0.113$ \\\\\n",
      "\\textsc{PoiPopularity} & $\\mathbf{0.701\\pm0.160}$ & $\\mathit{0.745\\pm0.166}$ & $0.620\\pm0.136$ & $0.663\\pm0.125$ & $0.678\\pm0.121$ \\\\\n",
      "\\textsc{PoiRank} & $\\mathit{0.700\\pm0.155}$ & $0.679\\pm0.123$ & $\\mathit{0.637\\pm0.142}$ & $0.640\\pm0.135$ & $0.600\\pm0.106$ \\\\\n",
      "\\textsc{Markov} & $0.645\\pm0.169$ & $0.722\\pm0.165$ & $0.577\\pm0.168$ & $0.697\\pm0.150$ & $0.669\\pm0.151$ \\\\\n",
      "\\textsc{MarkovPath} & $0.678\\pm0.149$ & $0.735\\pm0.170$ & $0.595\\pm0.148$ & $\\mathbf{0.706\\pm0.150}$ & $\\mathit{0.689\\pm0.139}$ \\\\\n",
      "\\textsc{Rank+Markov} & $0.659\\pm0.174$ & $0.722\\pm0.165$ & $0.613\\pm0.166$ & $0.697\\pm0.150$ & $0.669\\pm0.151$ \\\\\n",
      "\\textsc{Rank+MarkovPath} & $0.697\\pm0.152$ & $0.735\\pm0.170$ & $\\mathbf{0.639\\pm0.146}$ & $\\mathit{0.706\\pm0.150}$ & $0.689\\pm0.139$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = methods_all.copy() \n",
    "\n",
    "mean_df = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                       columns=dat_names, index=methods)\n",
    "std_df  = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                       columns=dat_names, index=methods)\n",
    "\n",
    "# new code\n",
    "lens_df = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                       columns=dat_names, index=methods)\n",
    "\n",
    "for dat_ix in range(len(dat_suffix)):\n",
    "    recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai = load_results(dat_ix)\n",
    "    means, stds, lens = calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai, func)\n",
    "    assert(len(means) == len(stds) == len(methods))\n",
    "    mean_df[dat_names[dat_ix]] = means\n",
    "    std_df[dat_names[dat_ix]]  = stds\n",
    "    \n",
    "    # new code\n",
    "    lens_df[dat_names[dat_ix]]  = lens\n",
    "\n",
    "ismax_df = pd.DataFrame(data=np.zeros(mean_df.shape, dtype=np.bool), columns=mean_df.columns, index=mean_df.index)\n",
    "ismax2nd_df = ismax_df.copy()\n",
    "for col in ismax_df.columns:\n",
    "    indices = (-mean_df[col]).argsort().values[:2]\n",
    "    ismax_df.iloc[indices[0]][col] = True\n",
    "    ismax2nd_df.iloc[indices[1]][col] = True\n",
    "\n",
    "if func == calc_F1:\n",
    "    title = '''Performance comparison on five datasets in terms of F$_1$ scores. \n",
    "    The best method for each dataset (i.e., a column) is shown in bold, the second best is shown in italic.'''\n",
    "    label = 'tab:f1'\n",
    "else:\n",
    "    title = '''Performance comparison on five datasets in terms of pairs-F$_1$ scores.\n",
    "    The best method for each dataset (i.e., a column) is shown in bold, the second best is shown in italic.'''\n",
    "    label = 'tab:pairf1'\n",
    "strs = gen_latex_table(mean_df, std_df, ismax_df, ismax2nd_df, title, label)\n",
    "\n",
    "print(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student's t-Test for Independent samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We omitted Edinbourgh and Melbourne, because even after 16 hours, we weren't getting close to the result. To calculate and evaluate significance tests for the results above, we implemented following structure.\n",
    "\n",
    "There is a total of 9 methods. Each method is represented by corresponding index:\n",
    "* __0__ - Random baseline\n",
    "* __1__ - PersTour\n",
    "* __2__ - PersTour-L\n",
    "* __3__ - PoiPopularity\n",
    "* __4__ - PoiRank\n",
    "* __5__ - Markov\n",
    "* __6__ - MarkovPath\n",
    "* __7__ - Rank+Markov\n",
    "* __8__ - Rank+MarkovPath\n",
    "\n",
    "Also, we have to omit Edinbourgh and Melbourne datasets, because even after 16 hours, the run wasn't finished. So there is a total of 3 cities, each city has its corresponding index:\n",
    "* __0__ - Glasgow\n",
    "* __1__ - Osaka\n",
    "* __2__ - Toronto\n",
    "\n",
    "In the paper, authors stated these facts about performance:\n",
    "\n",
    "* all algorithms outperformed random baseline on all datasets\n",
    "* PoiPopularity outperformed PoiRank\n",
    "* Rank+Markov outperformed Markov \n",
    "* Rank+MarkovPath outperformed MarkovPath\n",
    "* PersTour outperformed PersTour-L\n",
    "\n",
    "In the cells below, we ran significance tests to confirm/reject these hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind_from_stats\n",
    "\n",
    "cities_list = ['Glasgow', 'Osaka', 'Toronto']\n",
    "\n",
    "methods_list = ['PersTour', 'PersTour-L', 'PoiPopularity', \\\n",
    "               'PoiRank', 'Markov', 'MarkovPath', \\\n",
    "               'Rank+Markov', 'Rank+MarkovPath']\n",
    "\n",
    "all_results_df = pd.DataFrame(data=np.zeros((len(cities_list), len(methods_list)), dtype=np.float), \\\n",
    "                       columns=methods_list, index=cities_list)\n",
    "\n",
    "# city arrays containing p-value for random vs all other methods\n",
    "glasgow_pvalue = []\n",
    "osaka_pvalue = []\n",
    "toronto_pvalue = []\n",
    "results_list = [glasgow_pvalue,osaka_pvalue, toronto_pvalue]   \n",
    "\n",
    "# Loop over cities\n",
    "for i in range(0, len(mean_df.columns)):\n",
    "    # Loop over methods\n",
    "    for j in range(0, len(mean_df.index)):\n",
    "        # random baseline method\n",
    "        if (j==0):\n",
    "            # makes the actual comparisons - random vs all others\n",
    "            for x in range(1,9):\n",
    "                tt=ttest_ind_from_stats(mean1=mean_df.values[j,i], std1=std_df.values[j,i], nobs1=lens_df.values[j,i],\n",
    "                             mean2=mean_df.values[j+x,i], std2=std_df.values[j+x,i], nobs2=lens_df.values[j+x,i],\n",
    "                             equal_var=False)                     \n",
    "                if i == 1:\n",
    "                    glasgow_pvalue.append(round(tt.pvalue,4))                                            \n",
    "                elif i == 3:\n",
    "                    osaka_pvalue.append(round(tt.pvalue,4))                        \n",
    "                elif i == 4:\n",
    "                    toronto_pvalue.append(round(tt.pvalue,4))                        \n",
    "                # print(mean_df.values[j,i],std_df.values[j,i],lens_df.values[j,i],j,i, \"|\", j,i , \"|\", tt.pvalue)\n",
    "\n",
    "# Create Resulting Dataframe from the city result arrays\n",
    "for i in range(0,len(cities_list)):\n",
    "    all_results_df.loc[cities_list[i]] = results_list[i]\n",
    "\n",
    "all_results_df.transpose().to_excel(r\"data\\Significance-Testing\\random_vs_others.xlsx\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersTour</th>\n",
       "      <th>PersTour-L</th>\n",
       "      <th>PoiPopularity</th>\n",
       "      <th>PoiRank</th>\n",
       "      <th>Markov</th>\n",
       "      <th>MarkovPath</th>\n",
       "      <th>Rank+Markov</th>\n",
       "      <th>Rank+MarkovPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Osaka</th>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>0.4219</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PersTour  PersTour-L  PoiPopularity  PoiRank  Markov  MarkovPath  \\\n",
       "Glasgow    0.0000      0.0440         0.0000   0.0025   0.000       0.000   \n",
       "Osaka      0.0797      0.0143         0.0861   0.4219   0.007       0.003   \n",
       "Toronto    0.0000      0.0000         0.0000   0.5404   0.000       0.000   \n",
       "\n",
       "         Rank+Markov  Rank+MarkovPath  \n",
       "Glasgow        0.000            0.000  \n",
       "Osaka          0.007            0.003  \n",
       "Toronto        0.000            0.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI popularity > poi_rank\n",
    "poi_rank_list = ['PoiRank']\n",
    "\n",
    "poipop_vs_poirank_df = pd.DataFrame(data=np.zeros((len(cities_list), len(poi_rank_list)), dtype=np.float), \\\n",
    "                       columns=poi_rank_list, index=cities_list)\n",
    "\n",
    "poi_rank_res = []\n",
    "\n",
    "# Loop over cities\n",
    "for i in range(0, len(mean_df.columns)):\n",
    "    # Loop over methods\n",
    "    for j in range(0, len(mean_df.index)):\n",
    "        # poi popularity method\n",
    "        if (j==3):\n",
    "            if i in (1,3,4):\n",
    "                tt=ttest_ind_from_stats(mean1=mean_df.values[j,i], std1=std_df.values[j,i], nobs1=lens_df.values[j,i],\n",
    "                             mean2=mean_df.values[j+1,i], std2=std_df.values[j+1,i], nobs2=lens_df.values[j+1,i],\n",
    "                             equal_var=False)\n",
    "                poi_rank_res.append(round(tt.pvalue,4))                                            \n",
    "                # print(mean_df.values[j,i],std_df.values[j,i],lens_df.values[j,i],j,i, \"|\", j,i , \"|\", tt.pvalue)\n",
    "            \n",
    "poipop_vs_poirank_df[poi_rank_list[0]] = poi_rank_res  \n",
    "\n",
    "poipop_vs_poirank_df.transpose().to_excel(r\"data\\Significance-Testing\\poipop_vs_poirank.xlsx\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoiRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Osaka</th>\n",
       "      <td>0.3858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PoiRank\n",
       "Glasgow   0.0010\n",
       "Osaka     0.3858\n",
       "Toronto   0.0000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poipop_vs_poirank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank+Markov > Markov\n",
    "\n",
    "markov_list = ['Markov']\n",
    "\n",
    "rankmarkov_vs_markov_df = pd.DataFrame(data=np.zeros((len(cities_list), len(markov_list)), dtype=np.float), \\\n",
    "                           columns=markov_list, index=cities_list)\n",
    "\n",
    "markov_res = []\n",
    "\n",
    "for i in range(0, len(mean_df.columns)):\n",
    "    for j in range(0, len(mean_df.index)):\n",
    "        # compare random vs others\n",
    "        if (j==7):\n",
    "            if i in (1,3,4):\n",
    "                tt=ttest_ind_from_stats(mean1=mean_df.values[j,i], std1=std_df.values[j,i], nobs1=lens_df.values[j,i],\n",
    "                             mean2=mean_df.values[j-2,i], std2=std_df.values[j-2,i], nobs2=lens_df.values[j-2,i],\n",
    "                             equal_var=False)\n",
    "                markov_res.append(round(tt.pvalue,4))                                            \n",
    "            \n",
    "rankmarkov_vs_markov_df[markov_list[0]] = markov_res   \n",
    "rankmarkov_vs_markov_df.transpose().to_excel(r\"data\\Significance-Testing\\rankmarkov_vs_markov.xlsx\", index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Markov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Osaka</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Markov\n",
       "Glasgow     1.0\n",
       "Osaka       1.0\n",
       "Toronto     1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankmarkov_vs_markov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank+MarkovPath > MarkovPath\n",
    "\n",
    "markovpath_list = ['MarkovPath']\n",
    "\n",
    "rankmarkovpath_markovpath_df = pd.DataFrame(data=np.zeros((len(cities_list), len(markovpath_list)), dtype=np.float), \\\n",
    "                       columns=markovpath_list, index=cities_list)\n",
    "\n",
    "markovpath_res = []\n",
    "\n",
    "for i in range(0, len(mean_df.columns)):\n",
    "    for j in range(0, len(mean_df.index)):\n",
    "        # compare random vs others\n",
    "        if (j==8):\n",
    "            if i in (1,3,4):\n",
    "                tt=ttest_ind_from_stats(mean1=mean_df.values[j,i], std1=std_df.values[j,i], nobs1=lens_df.values[j,i],\n",
    "                             mean2=mean_df.values[j-2,i], std2=std_df.values[j-2,i], nobs2=lens_df.values[j-2,i],\n",
    "                             equal_var=False)\n",
    "                markovpath_res.append(round(tt.pvalue,4))                                            \n",
    "            \n",
    "rankmarkovpath_markovpath_df[markovpath_list[0]] = markovpath_res        \n",
    "rankmarkovpath_markovpath_df.transpose().to_excel(r\"data\\Significance-Testing\\rankmarkovpath_markovpath.xlsx\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarkovPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Osaka</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>0.9944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MarkovPath\n",
       "Glasgow      1.0000\n",
       "Osaka        1.0000\n",
       "Toronto      0.9944"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankmarkovpath_markovpath_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PersTour > PersTour-L\n",
    "\n",
    "perstour_list = ['PersTour-L']\n",
    "\n",
    "perstour_vs_perstourl_df = pd.DataFrame(data=np.zeros((len(cities_list), len(perstour_list)), dtype=np.float), \\\n",
    "                       columns=perstour_list, index=cities_list)\n",
    "\n",
    "prestour_res = []\n",
    "\n",
    "for i in range(0, len(mean_df.columns)):\n",
    "    for j in range(0, len(mean_df.index)):\n",
    "        # compare random vs others\n",
    "        if (j==1):\n",
    "            if i in (1,3,4):\n",
    "                tt=ttest_ind_from_stats(mean1=mean_df.values[j,i], std1=std_df.values[j,i], nobs1=lens_df.values[j,i],\n",
    "                             mean2=mean_df.values[j+1,i], std2=std_df.values[j+1,i], nobs2=lens_df.values[j+1,i],\n",
    "                             equal_var=False)\n",
    "                prestour_res.append(round(tt.pvalue,4))                                            \n",
    "            \n",
    "perstour_vs_perstourl_df[perstour_list[0]] = prestour_res  \n",
    "perstour_vs_perstourl_df.transpose().to_excel(r\"data\\Significance-Testing\\perstour_vs_perstourl.xlsx\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersTour-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Osaka</th>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PersTour-L\n",
       "Glasgow      0.0000\n",
       "Osaka        0.9991\n",
       "Toronto      0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(perstour_vs_perstourl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
